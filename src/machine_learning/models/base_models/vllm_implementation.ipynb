{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T11:58:18.214848Z",
     "start_time": "2025-04-24T11:58:18.193421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Math-7B\")\n",
    "\n",
    "# Pass the default decoding hyperparameters of Qwen2.5-7B-Instruct\n",
    "# max_tokens is for the maximum length for generation.\n",
    "sampling_params = SamplingParams(temperature=0.7, top_p=0.8, repetition_penalty=1.05, max_tokens=512)\n",
    "\n",
    "# Input the model name or path. Can be GPTQ or AWQ models.\n",
    "llm = LLM(model=\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "\n",
    "# Prepare your prompts\n",
    "prompt = \"Tell me something about large language models.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n"
   ],
   "id": "3a62f1425d45e82c",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LLM, SamplingParams\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Initialize the tokenizer\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'transformers'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T19:59:23.171020Z",
     "start_time": "2025-04-21T19:58:40.783369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# generate outputs\n",
    "outputs = llm.generate([text], sampling_params)\n",
    "\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ],
   "id": "7c29aa1bd200698e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-21 21:58:43 [cpu.py:170] Pin memory is not supported on CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:42<00:00, 42.38s/it, est. speed input: 0.87 toks/s, output: 11.35 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nTell me something about large language models.<|im_end|>\\n<|im_start|>assistant\\n', Generated text: \"Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are typically based on deep learning techniques, particularly transformer architectures, which allow them to process vast amounts of textual data and learn complex patterns in language.\\n\\nHere are some key points about large language models:\\n\\n1. **Scale**: LLMs can contain billions or even trillions of parameters, which allows them to capture intricate details and nuances in language. The larger the model, generally, the more sophisticated its understanding and generation capabilities.\\n\\n2. **Training Data**: These models are trained on massive datasets that include a wide variety of texts from the internet, books, articles, and other sources. This extensive training helps them to understand context, generate coherent text, and perform various language tasks.\\n\\n3. **Applications**: LLMs have a broad range of applications, including but not limited to:\\n   - **Text Generation**: Creating coherent paragraphs, stories, or even entire documents.\\n   - **Translation**: Translating text from one language to another with high accuracy.\\n   - **Chatbots and Virtual Assistants**: Providing natural and helpful responses to user queries.\\n   - **Content Creation**: Generating summaries, writing articles, and creating scripts.\\n   - **Language Understanding**: Improving search engines, chatbots, and other applications that need to understand and respond to human language.\\n\\n4. **Limitations**: Despite their capabilities, LLMs still have limitations such as:\\n   - **Bias and Fairness**: They can reflect biases present in their training data, which can lead to unfair or discriminatory outcomes.\\n   - **Misinformation**: They may generate false information if they have learned from inaccurate or misleading data.\\n   - **Overfitting**: Large models can sometimes produce overly complex outputs that don't generalize well to new, unseen data.\\n\\n5. **Ethical Considerations**: The development and deployment of LLMs raise important ethical questions, including privacy concerns, misuse potential, and the impact on jobs and society.\\n\\n6. **Research and Development**: There is ongoing research to improve the performance, efficiency, and ethical considerations of these models. This includes efforts to reduce their carbon footprint, enhance their interpretability, and mitigate biases.\\n\\nLarge language models represent a significant advancement in AI technology and continue to evolve rapidly, offering both exciting opportunities and challenges for developers, researchers, and end-users alike.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef037a374e452e67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
